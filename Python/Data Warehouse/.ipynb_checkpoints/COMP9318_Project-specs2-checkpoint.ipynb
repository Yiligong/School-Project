{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deadline + Late Penalty\n",
    "\n",
    "**Note :** It will take you quite some time to complete this project, therefore, we earnestly recommend that you start working as early as possible.\n",
    "\n",
    "\n",
    "* Submission deadline for the Project is **20:59:59 on 24th Apr, 2020 (Sydney Time)**.\n",
    "* **LATE PENALTY: Late Penalty: 10-% on day-1 and 20% on each subsequent day.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "1. This note book contains instructions for **COMP9318-Project**.\n",
    "\n",
    "2. You are required to complete your implementation in a file `submission.py` provided along with this notebook.\n",
    "\n",
    "3. You are not allowed to print out unnecessary stuff. We will not consider any output printed out on the screen. All results should be returned in appropriate data structures via corresponding functions.\n",
    "\n",
    "4. You can submit your implementation for **Project** via following link: http://kg.cse.unsw.edu.au/submit/ (for students in China use https://unswkg.net/submit/).\n",
    "\n",
    "5. For each question, we have provided you with detailed instructions along with question headings. In case of any problem, you can post your query @ Piazza.\n",
    "\n",
    "6. You are allowed to add other functions and/or import modules (you may have for this project), but you are not allowed to define global variables. **Only functions are allowed** in `submission.py`. \n",
    "\n",
    "7. We only support the following modules/libraries, importing other modules will lead to errors. \n",
    " * **Scipy 1.4.1**\n",
    " * **Numpy 1.81.6**\n",
    " * **Python 3.6**\n",
    "\n",
    "8. We will provide immediate feedback on your submission **based on small sample testcases**. You can view the feedback using the online submission portal on the same day.\n",
    "\n",
    "9. For **Final Evaluation** we will be using more different testcases, so your final scores **may vary** even you have passed the testcase. \n",
    "\n",
    "10. You are allowed to have a limited number of Feedback Attempts **(15 Attempts for each Team)**, we will use your **LAST** submission for Final Evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part1: PQ for $L_1$ Distance (45 Points)\n",
    "\n",
    "In this question, you will implement the product quantization method with $L_1$ distance as the distance function. **Note** that due to the change of distance function, the PQ method introduced in the class no longer works. You need to work out how to adjust the method and make it work for $L_1$ distance. For example, the K-means clustering algorithm works for $L_2$ distance, you need to implement its $L_1$ variants (we denote it as K-means* in this project). You will also need to explain your adjustments in the report later.\n",
    "\n",
    "Specifically, you are required to write a method `pq()` in the file `submission.py` that takes FOUR arguments as input:\n",
    "\n",
    "1. **data** is an array with shape (N,M) and dtype='float32', where N is the number of vectors and M is the dimensionality.\n",
    "2. **P** is the number of partitions/blocks the vector will be split into. Note that in the examples from the inverted multi index paper, P is set to 2. But in this project, you are required to implement a more general case where P can be any integer >= 2. You can assume that P is always divides M in this project. \n",
    "3. **init_centroids** is an array with shape (P,K,M/P) and dtype='float32', which corresponds to the initial centroids for P blocks. For each block, K M/P-dim vectors are used as the initial centroids. **Note** that in this project, K is fixed to be 256.\n",
    "4. **max_iter** is the maximum number of iterations of the K-means* clustering algorithm. **Note** that in this project, the stopping condition of K-means* clustering is that the algorithm has run for ```max_iter``` iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return Format (Part 1)\n",
    "\n",
    "The `pq()` method returns a codebook and codes for the data vectors, where\n",
    "* **codebooks** is an array with shape (P, K, M/P) and dtype='float32', which corresponds to the PQ codebooks for the inverted multi-index. E.g., there are P codebooks and each one has K M/P-dimensional codewords.\n",
    "* **codes** is an array with shape (N, P) and dtype=='uint8', which corresponds to the codes for the data vectors. The dtype='uint8' is because K is fixed to be 256 thus the codes should integers between 0 and 255. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manhattan distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pdfs.semanticscholar.org/a630/316f9c98839098747007753a9bb6d05f752e.pdf  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product Quantization\n",
    "\n",
    "https://hal.inria.fr/inria-00514462v1/document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.spatial import distance\n",
    "import submission\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_star(data,centroids,max_iter):  ## return 类型不对\n",
    "    k = 1\n",
    "    c_shape0 = centroids.shape[0]\n",
    "    codes = np.empty((data.shape[0],1),dtype=np.uint8)\n",
    "    codes[:] = np.NaN\n",
    "    centroids = centroids.astype(np.float32)\n",
    "    while k <= max_iter:     \n",
    "        for i in range(data.shape[0]):\n",
    "            d_manht = distance.cdist([data[i]],centroids,'cityblock')\n",
    "            index = np.argmin(d_manht)\n",
    "            codes[i] = index\n",
    "        \n",
    "        for j in range(c_shape0):\n",
    "            lk = np.argwhere(codes == j)\n",
    "            if lk.size > 0:\n",
    "                cluster_list = [data[x[0]] for x in lk]\n",
    "                centroids[j] = np.median(cluster_list,axis=0)\n",
    "\n",
    "        k+=1\n",
    "        \n",
    "    for i in range(data.shape[0]):\n",
    "            d_manht = distance.cdist([data[i]],centroids,'cityblock')\n",
    "            index = np.argmin(d_manht)\n",
    "            codes[i] = index\n",
    "    return codes, centroids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pq(data, P, init_centroids, max_iter): ##data is (768,128),init_centroids is (2,256,64)\n",
    "    offset = init_centroids.shape[2]\n",
    "    j = 0\n",
    "    k = offset\n",
    "    a = []\n",
    "    b = []\n",
    "    for i in range(P):\n",
    "        data_x = data[:,j:k*(i+1)]  #shape 768,64\n",
    "        codes, codebooks = K_star(data_x,init_centroids[i],max_iter)\n",
    "        a.append(codebooks)\n",
    "        b.append(codes)\n",
    "        j = k*(i+1)\n",
    "    codes = np.concatenate(b,axis=1)\n",
    "    codebooks = np.array(a)\n",
    "    return codebooks,codes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./example/CodeBooks_1', 'rb') as f:\n",
    "    CodeBooks_1 = pickle.load(f, encoding = 'bytes') #shape 2,256,64\n",
    "with open('./example/Data_File_1', 'rb') as f:\n",
    "    Data_File_1 = pickle.load(f, encoding = 'bytes') #shape 2,256,64\n",
    "with open('./example/Centroids_File_1', 'rb') as f:\n",
    "    Centroids_File_1 = pickle.load(f, encoding = 'bytes') #shape 2,256,64\n",
    "with open('./example/Codes_1', 'rb') as f:\n",
    "    Codes_1 = pickle.load(f, encoding = 'bytes') #shape 2,256,64\n",
    "start = time.time()\n",
    "codebooks, codes = pq(Data_File_1, P=2, init_centroids=Centroids_File_1, max_iter = 20)\n",
    "end = time.time()\n",
    "time_cost_1 = end - start\n",
    "# print(time_cost_1)\n",
    "# print(codebooks.dtype)\n",
    "# print(codebooks)\n",
    "# print(\"-------\")\n",
    "# print(CodeBooks_1.dtype)\n",
    "# print(CodeBooks_1)\n",
    "# print(\"-------\")\n",
    "# print(codes[:10])\n",
    "# print(\"-0-----\")\n",
    "# print(Codes_1[:10])\n",
    "\n",
    "np.savetxt('codes.txt', codes, delimiter=',')   # X is an array\n",
    "np.savetxt('Codes_1.txt', Codes_1, delimiter=',')   # X is an array\n",
    "#np.savetxt('codebooks.txt', codebooks, delimiter=',')   # X is an array\n",
    "#np.savetxt('', CodeBooks_1, delimiter=',')   # X is an array\n",
    "# ll = np.array([Data_File_1[:,:64][x] for x in range(3)])\n",
    "# print(Data_File_1[:,:64])\n",
    "# print(\"--------\")\n",
    "# print(ll)\n",
    "# print(\"--------\")\n",
    "# print(np.median(ll,axis=0))\n",
    "# print(np.median(ll[:,1]))\n",
    "# print(codebooks)\n",
    "# print(CodeBooks_1)\n",
    "# print(codes)\n",
    "# print(\"-------\")\n",
    "# print(Codes_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{512, 3, 516, 536, 538, 28, 543, 544, 545, 38, 557, 57, 72, 588, 592, 82, 83, 89, 601, 615, 103, 626, 628, 634, 642, 130, 643, 650, 146, 659, 660, 150, 668, 160, 673, 675, 163, 167, 690, 182, 187, 706, 197, 202, 209, 212, 726, 214, 221, 229, 231, 233, 236, 752, 756, 247, 761, 762, 763, 767, 770, 259, 779, 784, 277, 285, 802, 807, 828, 316, 318, 321, 834, 323, 352, 873, 367, 369, 882, 371, 375, 382, 900, 389, 392, 393, 910, 413, 414, 419, 422, 423, 936, 950, 962, 972, 989, 996, 489, 504}, {2, 516, 4, 13, 16, 26, 29, 32, 544, 49, 51, 57, 60, 65, 582, 585, 588, 78, 83, 94, 615, 103, 105, 618, 108, 115, 130, 645, 134, 172, 690, 178, 696, 193, 206, 209, 741, 743, 745, 756, 757, 758, 244, 250, 762, 255, 777, 783, 272, 274, 789, 279, 797, 291, 808, 309, 310, 311, 312, 825, 316, 830, 831, 322, 325, 330, 345, 864, 352, 356, 868, 870, 359, 879, 370, 906, 911, 914, 405, 409, 420, 423, 425, 427, 943, 433, 948, 438, 955, 958, 453, 456, 462, 975, 476, 481, 482, 485, 492, 497}, {4, 6, 521, 15, 17, 22, 23, 26, 28, 540, 543, 556, 570, 61, 65, 584, 606, 609, 102, 103, 105, 617, 619, 110, 641, 129, 643, 642, 133, 135, 140, 660, 150, 151, 665, 158, 679, 169, 182, 696, 700, 190, 197, 199, 717, 206, 723, 234, 762, 774, 268, 786, 277, 278, 792, 286, 802, 291, 293, 294, 296, 299, 812, 815, 310, 825, 828, 319, 832, 837, 854, 856, 360, 873, 876, 367, 369, 900, 398, 910, 400, 405, 929, 930, 933, 424, 425, 428, 940, 942, 434, 948, 955, 448, 450, 972, 979, 986, 991, 503}, {514, 515, 27, 30, 37, 45, 49, 564, 570, 59, 65, 67, 69, 595, 90, 100, 103, 615, 108, 109, 630, 638, 127, 128, 133, 137, 142, 143, 144, 667, 669, 167, 682, 175, 692, 699, 190, 706, 707, 201, 713, 716, 723, 733, 225, 739, 229, 231, 234, 236, 754, 755, 756, 246, 761, 764, 256, 277, 278, 281, 801, 806, 295, 808, 815, 825, 827, 830, 321, 330, 331, 852, 853, 341, 886, 889, 377, 899, 900, 905, 906, 398, 910, 403, 405, 918, 424, 427, 947, 950, 443, 957, 453, 455, 969, 462, 974, 988, 481, 502}, {513, 4, 11, 15, 529, 18, 535, 28, 29, 32, 33, 51, 564, 574, 576, 70, 72, 82, 83, 601, 102, 103, 617, 112, 630, 120, 649, 153, 673, 675, 166, 167, 680, 172, 684, 689, 696, 707, 206, 214, 217, 736, 738, 739, 229, 754, 758, 769, 264, 276, 284, 800, 290, 808, 812, 301, 815, 816, 307, 830, 323, 324, 325, 837, 849, 337, 852, 346, 350, 864, 868, 358, 871, 361, 878, 367, 371, 373, 886, 894, 896, 899, 388, 411, 422, 423, 936, 940, 432, 439, 453, 965, 982, 474, 987, 476, 991, 482, 483, 488}, {525, 15, 26, 28, 29, 32, 45, 563, 570, 60, 61, 584, 594, 600, 601, 602, 606, 609, 610, 103, 617, 110, 121, 127, 641, 137, 651, 139, 143, 149, 672, 680, 169, 690, 181, 694, 182, 696, 697, 186, 188, 714, 206, 723, 212, 217, 741, 751, 239, 248, 762, 763, 777, 789, 792, 284, 285, 809, 813, 825, 827, 319, 832, 325, 330, 331, 858, 865, 868, 870, 359, 873, 367, 897, 386, 899, 392, 393, 906, 403, 405, 407, 412, 927, 933, 425, 940, 955, 450, 453, 456, 974, 977, 981, 470, 991, 993, 481, 504, 508}, {515, 13, 22, 539, 32, 545, 39, 49, 566, 567, 574, 69, 70, 585, 586, 590, 82, 83, 601, 602, 608, 102, 103, 617, 111, 630, 633, 637, 639, 130, 643, 644, 133, 649, 655, 659, 156, 157, 167, 680, 688, 696, 186, 705, 712, 204, 212, 729, 230, 745, 750, 754, 243, 244, 246, 761, 255, 256, 777, 278, 281, 285, 296, 317, 832, 321, 836, 325, 839, 841, 337, 346, 862, 878, 886, 894, 899, 388, 903, 403, 917, 924, 415, 928, 420, 932, 427, 948, 438, 963, 453, 455, 457, 974, 975, 465, 476, 991, 483, 509}, {2, 3, 516, 521, 538, 543, 38, 39, 43, 558, 563, 52, 564, 59, 576, 584, 588, 80, 83, 89, 610, 105, 110, 111, 630, 639, 127, 643, 132, 133, 645, 137, 651, 652, 675, 679, 683, 177, 698, 708, 200, 201, 206, 217, 221, 231, 236, 764, 767, 259, 772, 775, 782, 789, 281, 796, 284, 801, 808, 816, 828, 318, 321, 850, 853, 354, 868, 360, 361, 382, 383, 387, 388, 389, 393, 910, 398, 414, 927, 928, 424, 936, 942, 943, 432, 438, 950, 959, 962, 455, 457, 461, 462, 976, 472, 476, 477, 991, 491, 500}, {2, 515, 7, 11, 529, 537, 34, 546, 556, 560, 566, 567, 58, 575, 588, 81, 83, 600, 601, 91, 606, 103, 618, 110, 643, 133, 143, 147, 663, 666, 156, 674, 687, 696, 202, 717, 720, 724, 214, 229, 231, 745, 234, 750, 754, 761, 762, 264, 779, 278, 279, 791, 284, 801, 813, 308, 821, 313, 317, 320, 321, 836, 327, 843, 338, 852, 853, 856, 345, 862, 353, 355, 356, 868, 370, 371, 372, 374, 376, 379, 381, 894, 896, 899, 392, 912, 917, 414, 928, 416, 932, 961, 453, 467, 984, 476, 480, 490, 492, 494}, {4, 525, 534, 26, 559, 560, 566, 65, 582, 584, 585, 82, 83, 616, 108, 630, 133, 137, 653, 657, 156, 669, 157, 160, 674, 163, 689, 177, 181, 185, 186, 187, 199, 713, 716, 722, 221, 222, 230, 746, 236, 237, 238, 243, 758, 255, 269, 783, 787, 791, 798, 809, 811, 821, 309, 322, 323, 325, 336, 340, 855, 346, 867, 359, 366, 884, 886, 387, 899, 389, 903, 392, 905, 395, 911, 914, 403, 926, 927, 417, 932, 422, 423, 936, 937, 945, 948, 950, 952, 444, 447, 959, 455, 460, 469, 477, 483, 487, 504, 509}]\n",
      "(1000, 4)\n"
     ]
    }
   ],
   "source": [
    "with open('./example/CodeBooks_2', 'rb') as f:\n",
    "    CodeBooks_2 = pickle.load(f, encoding = 'bytes') #shape 2,256,64\n",
    "with open('./example/Data_File_2', 'rb') as f:\n",
    "    Data_File_2 = pickle.load(f, encoding = 'bytes') #shape 2,256,64\n",
    "with open('./example/Centroids_File_2', 'rb') as f:\n",
    "    Centroids_File_2 = pickle.load(f, encoding = 'bytes') #shape 2,256,64\n",
    "with open('./example/Codes_2', 'rb') as f:\n",
    "    Codes_2 = pickle.load(f, encoding = 'bytes') #shape 2,256,64\n",
    "with open('./example/Candidates_2', 'rb') as f:\n",
    "    Candidates_2 = pickle.load(f, encoding = 'bytes') #shape 2,256,64\n",
    "start = time.time()\n",
    "codebooks2, codes2 = pq(Data_File_2, P=4, init_centroids=Centroids_File_2, max_iter = 20)\n",
    "end = time.time()\n",
    "time_cost_1 = end - start\n",
    "print(Candidates_2)\n",
    "print(Codes_2.shape)\n",
    "# print(time_cost_1)\n",
    "# np.savetxt('codes2.txt', codes2, delimiter=',')   # X is an array\n",
    "# np.savetxt('Codes_2.txt', Codes_2, delimiter=',')   # X is an array\n",
    "# print(codebooks2.dtype)\n",
    "# print(codebooks2)\n",
    "# print(\"-------\")\n",
    "# print(CodeBooks_2.dtype)\n",
    "# print(CodeBooks_2)\n",
    "# print(\"-------\")\n",
    "# print(codes2.dtype)\n",
    "# print(codes2)\n",
    "# print(\"-0-----\")\n",
    "# print(Codes_2.dtype)\n",
    "# print(Codes_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How to run your implementation for Part 1\n",
    "with open('./toy_example/Data_File', 'rb') as f:\n",
    "    Data_File = pickle.load(f, encoding = 'bytes') #shape 768,128\n",
    "with open('./toy_example/Centroids_File', 'rb') as f:\n",
    "    Centroids_File = pickle.load(f, encoding = 'bytes') #shape 2,256,64\n",
    "# print(\"ds\",Centroids_File)\n",
    "# print(\"ds\",Data_File)\n",
    "start = time.time()\n",
    "codebooks, codes = pq(Data_File, P=2, init_centroids=Centroids_File, max_iter = 20)\n",
    "end = time.time()\n",
    "time_cost_1 = end - start\n",
    "# print(time_cost_1)\n",
    "# #print(type(codes))\n",
    "# #print(codebooks.shape)\n",
    "# #print(codebooks)\n",
    "# print(codes.dtype)\n",
    "# print(codebooks.dtype)\n",
    "# print(Centroids_File)\n",
    "#a = Data_File[:,:64]\n",
    "# for i in a:\n",
    "#     print(np.argmin(distance.cdist([i],Centroids_File[0,:,:64],'cityblock')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = np.empty((3,4))\n",
    "nn[:] = np.NaN\n",
    "nn[:] = 1\n",
    "nn.astype(np.uint8)\n",
    "np.argwhere(nn == 1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part2: Query using Inverted Multi-index with $L_1$ Distance (45 Points)\n",
    "\n",
    "In this question, you will implement the query method using the idea of inverted multi-index with $L_1$ distance. Specifically, you are required to write a method `query()` in the file `submission.py` that takes arguments as input:\n",
    "\n",
    "1. **queries** is an array with shape (Q, M) and dtype='float32', where Q is the number of query vectors and M is the dimensionality.\n",
    "2. **codebooks** is an array with shape (P, K, M/P) and dtype='float32', which corresponds to the `codebooks` returned by `pq()` in part 1.\n",
    "3. **codes** is an array with shape (N, P) and dtype=='uint8', which corresponds to the `codes` returned by `pq()` in part 1.\n",
    "4. **T** is an integer which indicates the minimum number of returned candidates for each query. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Return Format (Part 2)\n",
    "\n",
    "The `query()` method returns an array contains the candidates for each query. Specifically, it returns\n",
    "* **candidates** is a list with Q elements, where the i-th element is a **set** that contains at least T integers, corresponds to the id of the candidates of the i-th query. For example, assume $T=10$, for some query we have already obtained $9$ candidate points. Since $9 < T$, the algorithm continues. Assume the next retrieved cell contains $3$ points, then the returned set will contain $12$ points in total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation Hints\n",
    "\n",
    "The implementation of `query()` should be efficiency. You should work out at least\n",
    "1. How to efficiently extend Algorithm 3.1 in the paper to a general case with P > 2.\n",
    "2. How to efficiently make use of `codes` returned by Part 1. For example, it may not be wise to enumerate all the possible combinations of codewords to build the inverted index. \n",
    "\n",
    "We will test the efficiency by setting a running time limit (more details later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0],\n",
       "       [  0,   0],\n",
       "       [  0,   0],\n",
       "       ...,\n",
       "       [255, 255],\n",
       "       [255, 255],\n",
       "       [255, 255]], dtype=uint8)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "codebooks, codes = submission.pq(Data_File, P=2, init_centroids=Centroids_File, max_iter = 20)\n",
    "end = time.time()\n",
    "time_cost_1 = end - start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2}"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = [0,0]\n",
    "#np.argwhere(codes==k)\n",
    "#np.squeeze(codes)\n",
    "d = np.argwhere(codes[:,0]==k[0])#.flatten()\n",
    "f = np.argwhere(codes[:,1]==k[1])#.flatten()\n",
    "k = np.intersect1d(d,f)\n",
    "a = set()\n",
    "a.update(k)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_seq(dist_matrix,codes,T):\n",
    "    x = dist_matrix.shape[0]  ## the number of partions\n",
    "    y = dist_matrix.shape[1]  ## the number of queries\n",
    "    z = dist_matrix.shape[2]  ## the number of centroids\n",
    "    traverse_arr = np.zeros((x,y,z+1))  ## get the array with appending 0s \n",
    "    for i in range(y):\n",
    "        queue = []\n",
    "        points_set = set()\n",
    "        queue.append([[1]*x,sum(dist_matrix[:,i,0,1]),dist_matrix[:,i,0,0]]) #第三维度的记住要减一\n",
    "        while len(points_set) < T:\n",
    "            #print(queue)\n",
    "            queue.sort(key=lambda x:x[1])\n",
    "            centroid = queue.pop(0)\n",
    "            index = centroid[-1]  ## the index of the centroids\n",
    "            matrix_index = centroid[0]\n",
    "            n = np.argwhere(codes[:,0]==index[0])\n",
    "            \n",
    "            for k in range(x):\n",
    "                traverse_arr[k,i,matrix_index[k]] = 1\n",
    "                \n",
    "            if len(index) > 1:\n",
    "                for j in range(1,x):\n",
    "                    n = np.intersect1d(n,np.argwhere(codes[:,j]==index[j]))\n",
    "            points_set.update(n)\n",
    "            \n",
    "            p_index = 0 ## the index of which partition\n",
    "            for m in matrix_index:\n",
    "                if m <= z and \n",
    "            ##if i < length(r) and (j=1 or traversed(i+1, j−1))\n",
    "            ##then pqueue.push ( (i+1, j), r(i+1)+s(j))\n",
    "            ##if j < length(s) and (i=1 or traversed(i−1, j+1))\n",
    "            ##then pqueue.push ( (i, j+1), r(i)+s(j+1))\n",
    "            print(traverse_arr)\n",
    "            #print(queue)\n",
    "        #print(points_set)\n",
    "        #print(dist_matrix[:,i,0,1])\n",
    "    #print(traverse_arr.shape)\n",
    "    # initialise traverse array 有几个partition就有几个值，那么每个值对应的是dist_matrix 最小原子的index,\n",
    "    #每个值对应的index就是partition的index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query(queries,codebooks,codes,T):\n",
    "    j = 0\n",
    "    dist_matrix = []\n",
    "    for e in codebooks:\n",
    "        i = j\n",
    "        j += e.shape[1]\n",
    "        sub_query = queries[:,i:j]\n",
    "        d = np.abs(sub_query[:,None]-e).sum(-1)\n",
    "        sort_d = np.sort(d)\n",
    "        argsort_d = np.argsort(d)\n",
    "        index_value = np.dstack((argsort_d,sort_d))\n",
    "        #index_value = np.abs(sub_query[:,None]-e).sum(-1)\n",
    "        dist_matrix.append(index_value)\n",
    "    dist_matrix = np.array(dist_matrix)\n",
    "    multi_seq(dist_matrix,codes,T)\n",
    "    #print(dist_matrix.shape)\n",
    "    #print(dist_matrix)\n",
    "        #print(sub_query[:,None] - e[:,:,None])\n",
    "        #print(e)\n",
    "        #print(sub_query,sub_query.shape)\n",
    "    #print(queries.shape,codebooks.shape,codes.shape)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "   0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# How to run your implementation for Part 2\n",
    "with open('./toy_example/Query_File', 'rb') as f:\n",
    "    Query_File = pickle.load(f, encoding = 'bytes')\n",
    "# with open('./example/Query_File_1', 'rb') as f:\n",
    "#     Query_File = pickle.load(f, encoding = 'bytes')\n",
    "queries = Query_File#pickle.load(Query_File, encoding = 'bytes')\n",
    "start = time.time()\n",
    "candidates = query(queries, codebooks, codes, T=3)\n",
    "end = time.time()\n",
    "time_cost_2 = end - start\n",
    "\n",
    "\n",
    "\n",
    "# a = codebooks[0]\n",
    "# #b = queries[:2,]\n",
    "# c = queries[:2,0]\n",
    "# # #print(Data_File.shape)\n",
    "# # # output for part 2.\n",
    "# # #print(candidates)\n",
    "# # print(\"codebook\",a)\n",
    "# # print(\"query\",c)\n",
    "# # print(a.shape,c.shape)\n",
    "# d = abs(c[:,None] - a).sum(-1)\n",
    "# i = np.argsort(d)\n",
    "# j = np.sort(d)\n",
    "# print(i[1])\n",
    "# print(j[1])\n",
    "# index_value = np.dstack((i,j))\n",
    "# #print(index_value.shape)\n",
    "# index_value\n",
    "# print(d[0].shape)\n",
    "# print(d.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "\n",
    "Your implementation will be tested using 3 testcases (**30 points each, and another 10 points from the report**), your result will be compared with the result of the correct implementation. Part 1 and part 2 will be test **seperately** (e.g., you may still get 45 points from part 2 even if you do not attempt part 1), and you will get full mark for each part if the output of your implementation matches the expected output and 0 mark otherwise. \n",
    "\n",
    "**Note:** One of these 3 testcases is the same as the one used in the **submssion system**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Inverted Multi-Index\n",
    "http://sites.skoltech.ru/app/data/uploads/sites/25/2014/12/TPAMI14.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to run your implementation (Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  2.,   2.,   2., ...,   2.,   2.,   2.],\n",
       "        [  5.,   5.,   5., ...,   5.,   5.,   5.],\n",
       "        [  8.,   8.,   8., ...,   8.,   8.,   8.],\n",
       "        ...,\n",
       "        [761., 761., 761., ..., 761., 761., 761.],\n",
       "        [764., 764., 764., ..., 764., 764., 764.],\n",
       "        [767., 767., 767., ..., 767., 767., 767.]],\n",
       "\n",
       "       [[  2.,   2.,   2., ...,   2.,   2.,   2.],\n",
       "        [  5.,   5.,   5., ...,   5.,   5.,   5.],\n",
       "        [  8.,   8.,   8., ...,   8.,   8.,   8.],\n",
       "        ...,\n",
       "        [761., 761., 761., ..., 761., 761., 761.],\n",
       "        [764., 764., 764., ..., 764., 764., 764.],\n",
       "        [767., 767., 767., ..., 767., 767., 767.]]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Time Limits\n",
    "\n",
    "As shown in the above snippet, we will be recording the running time of both part 1 and part 2. Your implementation is expected to finish with Allowed time Limit. If your code takes longer than Allowed Time Limit, your program will be terminated and you will recieve 0 mark.\n",
    "\n",
    "For example, on CSE machine, e.g., **wagner**, your code is supposed to finish with in 3 seconds (for part 1) and 1 second (for part 2) for the toy example illustrated above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Submission and Feedback\n",
    "\n",
    "For project submission, you are required to submit the following files:\n",
    "\n",
    "1. Your implementation in a python file `submission.py`.\n",
    "\n",
    "2. A report `Project.pdf` (**10 points**). You need to write a concise and simple report illustrating\n",
    "    - Implementation details of part 1, especially what changes you made to accomodate $L_1$ distance.\n",
    "    - Implementation details of part 2, including the details on how you extended the algorithm 3.1 to a more general case with P>2, and how you efficiently retrieve the candidates. \n",
    "\n",
    "\n",
    "**Note:** Every team will be entitled to **15 Feedback Attempts** (use them wisely), we will use the last submission for final evaluation."
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
