{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from datetime import datetime\n",
    "from sklearn import linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB,MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LinearRegression,BayesianRidge\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split,ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error,precision_score,recall_score,accuracy_score,confusion_matrix,r2_score\n",
    "\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#from sklearn.impute import SimpleImputer\n",
    "#from scipy.stats.stats import pearsonr\n",
    "#from sklearn.metrics import r2_score\n",
    "#from sklearn import preprocessing\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "#from sklearn.feature_extraction import DictVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/feature-selection-techniques-in-machine-learning-with-python-f24e7da3f36e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'training.csv'\n",
    "validation_file = 'validation.csv'"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cols                   length\n",
    "\n",
    "cast                   33449\n",
    "crew                   35516\n",
    "genres                 18\n",
    "keywords               6681\n",
    "production_companies   2361\n",
    "production_countries   52\n",
    "spoken_languages       66\n",
    "\n",
    "\n",
    "revenue 0.46       high bias low variance\n",
    "crew    0.0000595  high bias high variance\n",
    "release_date   0.021329892748176982  high bias low variance\n",
    "rating  0.03817    high bias low variance\n",
    "runtime 0.049024   high bias low variance\n",
    "\n",
    "cast, crew, budget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_column(df_train,df_valid,e,max_features=100):\n",
    "    count = CountVectorizer(max_features = max_features)\n",
    "    X = count.fit(df_train[e])\n",
    "    X_train = X.transform(df_train[e])\n",
    "    X_test = X.transform(df_valid[e])\n",
    "    X_train = pd.DataFrame(X_train.todense(),columns=count.get_feature_names())\n",
    "    X_test = pd.DataFrame(X_test.todense(),columns=count.get_feature_names())\n",
    "    return X_train,X_test\n",
    "\n",
    "def is_json(myjson):\n",
    "    try:\n",
    "        json_object = json.loads(myjson)\n",
    "    except:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def return_str(x,json_id):\n",
    "    return ','.join([item[f'{json_id}'].replace(\" \",\"\") for item in json.loads(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df_train,col_l,drop_cols):\n",
    "    df_train = df_train.drop(drop_cols,axis=1)\n",
    "    for col in col_l:\n",
    "        if col == 'spoken_languages':\n",
    "            df_train['spoken_languages'] = df_train['spoken_languages'].apply(lambda x: return_str(x,'iso_639_1'))\n",
    "        elif col == 'release_date':\n",
    "            #df_train['release_year'] = df_train['release_date'].apply(lambda x: int(x.split('-')[0]))\n",
    "            df_train['release_date'] = df_train['release_date'].apply(lambda x: datetime.strptime(x, '%Y-%m-%d').timetuple().tm_yday)\n",
    "            \n",
    "        else:\n",
    "            df_train[col] = df_train[col].apply(lambda x: return_str(x,'name'))\n",
    "    return df_train\n",
    "\n",
    "\n",
    "def get_encode_df(df_train,df_valid,col_l,drop_cols,col_names):\n",
    "    df_train = preprocess(df_train,col_l,drop_cols)\n",
    "    df_valid = preprocess(df_valid,col_l,drop_cols)\n",
    "    for e in col_names.keys():\n",
    "        df_encode_train,df_encode_valid = encode_column(df_train,df_valid,e,max_features=col_names[e])\n",
    "        df_train = pd.concat([df_train, df_encode_train],axis=1)\n",
    "        df_valid = pd.concat([df_valid, df_encode_valid],axis=1)\n",
    "        df_train = df_train.drop(e,axis=1)\n",
    "        df_valid = df_valid.drop(e,axis=1)\n",
    "    return df_train,df_valid\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_cv(X_train_cf,y_train_cf):\n",
    "    classifiers = [linear_model.Ridge(alpha=.5),\n",
    "                   LinearRegression(),\n",
    "                   linear_model.Lasso(alpha=0.1),\n",
    "                   tree.DecisionTreeRegressor(),\n",
    "                   linear_model.LassoLars(alpha=.1),\n",
    "                   linear_model.BayesianRidge(),\n",
    "                   svm.SVR(),\n",
    "                   RandomForestRegressor(n_estimators=100, oob_score=True, random_state=42),\n",
    "                   KNeighborsRegressor(n_neighbors=5)]\n",
    "    classifier_accuracy_list = []\n",
    "    for i, classifier in enumerate(classifiers):\n",
    "        accuracies = -cross_val_score(classifier, X_train_cf, y_train_cf, cv=5,scoring='neg_mean_squared_error')\n",
    "        classifier_accuracy_list.append((accuracies.mean(), type(classifier).__name__))\n",
    "\n",
    "    classifier_accuracy_list = sorted(classifier_accuracy_list, reverse=False)\n",
    "    for item in classifier_accuracy_list:\n",
    "        print(item[1], ':', item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_Gridsearch_regress():\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 5)]\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    max_depth = [int(x) for x in np.linspace(2, 100, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [2, 3, 4, 5, 6,7,8,9, 10]\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    bootstrap = [True, False]\n",
    "    warm_start = [True, False]\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap,\n",
    "                   'warm_start':warm_start}\n",
    "    rf = RandomForestRegressor()\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                                   param_distributions = \n",
    "                                   random_grid, \n",
    "                                   n_iter = 20, \n",
    "                                   cv = 3, \n",
    "                                   verbose=1, \n",
    "                                   random_state=8, \n",
    "                                   n_jobs = -1,\n",
    "                                   scoring='neg_mean_squared_error')\n",
    "    return rf_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression(df_train,df_valid):\n",
    "    \n",
    "    col_l = ['cast','crew','genres','keywords','production_companies','spoken_languages','release_date']\n",
    "    drop_cols = ['homepage','original_title','production_countries',\n",
    "                 'original_language','overview','status','rating','tagline'] #keep tagline\n",
    "    col_names = {'cast':50, #30\n",
    "                 'crew':200, #115\n",
    "                 'genres':10,\n",
    "                 'keywords':60,\n",
    "                 'production_companies':4,\n",
    "                 'spoken_languages':10\n",
    "                 }\n",
    "    train,valid = get_encode_df(df_train,df_valid,col_l,drop_cols,col_names)\n",
    "    \n",
    "    X_train = train.loc[:,~train.columns.isin(['movie_id','revenue'])]\n",
    "    y_train = train['revenue']\n",
    "    X_test = valid.loc[:,~valid.columns.isin(['movie_id','revenue'])]\n",
    "    y_test = valid['revenue']\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "\n",
    "    #regression_cv(X_train,y_train) # use grid to choose a best regression model\n",
    "    #rf_random = random_Gridsearch_regress().fit(X_train,y_train) #use random grid search find the best param\n",
    "    reg2 = RandomForestRegressor(n_estimators=200,\n",
    "                                 warm_start=False,\n",
    "                                min_samples_split=8,\n",
    "                                min_samples_leaf=1,\n",
    "                                max_features='auto',\n",
    "                                max_depth=100,\n",
    "                                bootstrap=True).fit(X_train,y_train)\n",
    "#     scores = cross_val_score(reg2, X_train, y_train, cv=5, scoring='r2')\n",
    "#     print(scores.mean())\n",
    "    y_pred2 = np.round(reg2.predict(X_test),decimals=2)\n",
    "    mse2 = float(\"{:.2f}\".format(mean_squared_error(y_test, y_pred2)))\n",
    "    coef_score2 = float(\"{:.2f}\".format(np.corrcoef(y_test,y_pred2)[0][1]))\n",
    "    r2 = r2_score(y_test,y_pred2)\n",
    "    print(\"r2\",r2)\n",
    "    print(\"RandomForest\",mse2,coef_score2)\n",
    "\n",
    "    df_summary = pd.DataFrame({'zid':'z5199285',\n",
    "                               'MSR':[mse2],\n",
    "                               'correlation':[coef_score2]})\n",
    "    \n",
    "    df_output = pd.DataFrame({'movie_id':valid['movie_id'],'predicted_revenue':y_pred2})\n",
    "    df_summary.to_csv('z5199285.PART1.summary.csv',index=False)\n",
    "    df_output.to_csv('z5199285.PART1.output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifi_cv(X_train_cf,y_train_cf):\n",
    "    classifiers = [KNeighborsClassifier(),\n",
    "               DecisionTreeClassifier(),\n",
    "               LinearDiscriminantAnalysis(),\n",
    "               LogisticRegression(),\n",
    "               GaussianNB(),\n",
    "               SVC(),\n",
    "               BernoulliNB(),\n",
    "               MultinomialNB(),\n",
    "               RandomForestClassifier(n_estimators=100)]\n",
    "    classifier_accuracy_list = []\n",
    "    for i, classifier in enumerate(classifiers):\n",
    "        accuracies = cross_val_score(classifier, X_train_cf, y_train_cf, cv=5,scoring='accuracy')\n",
    "        classifier_accuracy_list.append((accuracies.mean(), type(classifier).__name__))\n",
    "\n",
    "    classifier_accuracy_list = sorted(classifier_accuracy_list, reverse=True)\n",
    "    for item in classifier_accuracy_list:\n",
    "        print(item[1], ':', item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_Gridsearch_class():\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 1000, num = 5)]\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    max_depth = [int(x) for x in np.linspace(2, 100, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    min_samples_split = [2, 3, 4, 5, 6,7,8,9, 10]\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    bootstrap = [True, False]\n",
    "    warm_start = [True, False]\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap,\n",
    "                   'warm_start':warm_start}\n",
    "    rf = RandomForestClassifier()\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                                   param_distributions = \n",
    "                                   random_grid, \n",
    "                                   n_iter = 50, \n",
    "                                   cv = 3, \n",
    "                                   verbose=1, \n",
    "                                   random_state=8, \n",
    "                                   n_jobs = -1,\n",
    "                                   scoring='accuracy')\n",
    "    return rf_random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GridSearch():\n",
    "    bootstrap = [True]\n",
    "    max_depth = [10,20,30, 40, 50]\n",
    "    max_features = ['auto']\n",
    "    min_samples_leaf = [1, 2, 3, 4]\n",
    "    min_samples_split = [2, 3, 4, 5, 10, 15]\n",
    "    n_estimators = [100,200,300]\n",
    "\n",
    "    param_grid = {\n",
    "        'bootstrap': bootstrap,\n",
    "        'max_depth': max_depth,\n",
    "        'max_features': max_features,\n",
    "        'min_samples_leaf': min_samples_leaf,\n",
    "        'min_samples_split': min_samples_split,\n",
    "        'n_estimators': n_estimators\n",
    "    }\n",
    "\n",
    "    rfc = RandomForestClassifier(random_state=8)\n",
    "\n",
    "    cv_sets = ShuffleSplit(n_splits = 3, test_size = .33, random_state = 8)\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=rfc, \n",
    "                               param_grid=param_grid,\n",
    "                               scoring='accuracy',\n",
    "                               cv=cv_sets,\n",
    "                               verbose=1)\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification(df_train,df_valid):\n",
    "    col_l = ['cast','crew','genres','keywords','production_companies','spoken_languages','release_date']\n",
    "    drop_cols = ['homepage','original_title','production_countries',\n",
    "                 'original_language','overview','tagline','status','revenue']\n",
    "    col_names = {'cast':100, #30\n",
    "                 'crew':200, #115\n",
    "                 'genres':10,\n",
    "                 'keywords':40,\n",
    "                 'production_companies':4,\n",
    "                 'spoken_languages':10}\n",
    "    train,valid = get_encode_df(df_train,df_valid,col_l,drop_cols,col_names)\n",
    "    X_train = train.loc[:,~train.columns.isin(['movie_id','rating'])]\n",
    "    y_train = train['rating']\n",
    "    X_test = valid.loc[:,~valid.columns.isin(['movie_id','rating'])]\n",
    "    y_test = valid['rating']\n",
    "    #classifi_cv(X_train,y_train) #choose randomForest as our classifier\n",
    "    #rf_random = random_Gridsearch_class() #use random grid search find the best param\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=200,\n",
    "                                 warm_start=False,\n",
    "                                min_samples_split=2,\n",
    "                                min_samples_leaf=3,\n",
    "                                max_features='auto',\n",
    "                                max_depth=30,\n",
    "                                bootstrap=True).fit(X_train,y_train)\n",
    "#     grid_search = GridSearch() #use grid search to further tune the hyperparameter\n",
    "    y_predict = clf.predict(X_test)\n",
    "    y_train_predict = clf.predict(X_train)\n",
    "    cm = confusion_matrix(y_test,y_predict)\n",
    "    prec_score = float(\"{:.2f}\".format(precision_score(y_test,y_predict,average='macro')))\n",
    "    recal_score = float(\"{:.2f}\".format(recall_score(y_test,y_predict,average='macro')))\n",
    "    #print(rf_random.best_params_)\n",
    "    acc_score = float(\"{:.2f}\".format(accuracy_score(y_test,y_predict)))\n",
    "    print(prec_score,recal_score,acc_score)\n",
    "    print(accuracy_score(y_train,y_train_predict))\n",
    "    print(cm)\n",
    "    df_summary = pd.DataFrame({'zid':'z5199285',\n",
    "                               'average_precision':[prec_score],\n",
    "                               'average_recall':[recal_score],\n",
    "                               'accuracy':[acc_score]})\n",
    "    \n",
    "    df_output = pd.DataFrame({'movie_id':valid['movie_id'],'predicted_rating':y_predict})\n",
    "    df_summary.to_csv('z5199285.PART2.summary.csv',index=False)\n",
    "    df_output.to_csv('z5199285.PART2.output.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 0.23769368460805473\n",
      "RandomForest 6167884867353802.0 0.49\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_file = 'training.csv'#sys.argv[1]\n",
    "    validation_file = 'validation.csv'#sys.argv[2]\n",
    "    df_train = pd.read_csv(train_file)\n",
    "    df_valid = pd.read_csv(validation_file)\n",
    "    regression(df_train,df_valid)\n",
    "    #classification(df_train,df_valid)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best params\n",
    "{'warm_start': False, 'n_estimators': 600, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'auto', 'max_depth': 100, 'bootstrap': False}\n",
    "\n",
    "{'warm_start': False, 'n_estimators': 200, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 41, 'bootstrap': True}\n",
    "0.6966745667308547 0.6558803674679345 0.7425\n",
    "0.9847619047619047\n",
    "\n",
    "{'bootstrap': True, 'max_depth': 30, 'max_features': 'auto', 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 200}\n",
    "0.7200577200577201\n",
    "0.6720588235294118 0.6030201637756449 0.7225\n",
    "0.8361904761904762"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
